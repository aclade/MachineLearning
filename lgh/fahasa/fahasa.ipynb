{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAHASA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khởi Tạo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import urllib.request as urllib2\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "goc='https://www.fahasa.com/catalogsearch/result/?q=ti%E1%BB%83u+thuy%E1%BA%BFt+b%C3%A1n+ch%E1%BA%A1y' \n",
    "pages.append(goc)\n",
    "def get_links(trang):\n",
    "    for i in range(2,trang+1):\n",
    "        pages.append('https://www.fahasa.com/search/page/'+str(i)+'?q=ti%E1%BB%83u+thuy%E1%BA%BFt+b%C3%A1n+ch%E1%BA%A1y')\n",
    "get_links(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = []\n",
    "img = []\n",
    "loun = []\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36\"}\n",
    "\n",
    "def take_name_and_img(url):\n",
    "    r = requests.get(url,headers=headers)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    s = soup.find_all('span', class_ ='product-image')\n",
    "    for ptd in s:\n",
    "        tam = ptd.find('img')\n",
    "        lon.append(tam['alt'])\n",
    "        img.append(tam['src'])\n",
    "    s = soup.find_all('a', class_='product-image')\n",
    "    for ptd in s:\n",
    "        loun.append(ptd['href'])\n",
    "    \n",
    "for url in pages:\n",
    "    take_name_and_img(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lop = []\n",
    "loa = []\n",
    "genre = []\n",
    "\n",
    "def take_prices_inf_genre(url):\n",
    "    r = requests.get(url,headers=headers)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    s = soup.find('span',class_='price')\n",
    "    lop.append(s.text)\n",
    "    s = soup.find('div',class_='std')\n",
    "    loa.append(s.text)\n",
    "    s = soup.find('ol',class_='breadcrumb').find_all('a')\n",
    "    temp = []\n",
    "    for ptd in s:\n",
    "        temp.append(ptd.text)\n",
    "    genre.append(temp)\n",
    "\n",
    "for url in loun:\n",
    "    take_prices_inf_genre(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pro={\"Tên \": lon,\"Gia \": lop ,\"Thong tin\": loa,\"Anh\":img,\"The loai\":genre}\n",
    "df=pd.DataFrame(dict_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"lgh.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "839e0350e26a03edc91ebdedcb53fe8f541802bd102f926973002a967871fd0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
