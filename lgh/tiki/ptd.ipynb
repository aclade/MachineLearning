{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WED SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khởi Tạo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "goc='https://tiki.vn/search?q=ti%E1%BB%83u+thuy%E1%BA%BFt&sort=top_seller&page=' \n",
    "def get_links(trang):\n",
    "    for i in range(1,trang+1):\n",
    "        pages.append(goc+str(i))\n",
    "get_links(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon=[]\n",
    "lop=[]\n",
    "loun=[]\n",
    "sort = []\n",
    "dem = 0\n",
    "def take_name_and_prices(url):\n",
    "    html=urlopen(url) \n",
    "    bs = BeautifulSoup(html.read(), 'html.parser') \n",
    "    \n",
    "\n",
    "    if url[len(url)-2] != '=':\n",
    "        c = url[len(url)-2]+url[len(url)-1]\n",
    "    else :\n",
    "        c ='0'+ url[len(url)-1]\n",
    "    for i in range(1,40+1):\n",
    "        if i < 10:\n",
    "            temp = '0'+str(i)\n",
    "        else : \n",
    "            temp = str(i)\n",
    "        sort.append(c+temp)\n",
    "\n",
    "        \n",
    "    tam = bs.find_all('div',class_='name')    \n",
    "    for i in tam :\n",
    "        lon.append(i.text)\n",
    "            \n",
    "    product_prices=bs.find_all('div',class_='price-discount__price')\n",
    "        \n",
    "    for element in product_prices:\n",
    "        lop.append(element.text)\n",
    "        \n",
    "    site='https://tiki.vn'\n",
    "    lou=[]\n",
    "        \n",
    "    urls=bs.find_all('a', class_='product-item')    \n",
    "    for url in urls:\n",
    "        lou.append(url['href']) \n",
    "    for url in lou:    \n",
    "        urlnew='{}{}'.format(site, url)\n",
    "        loun.append(urlnew)\n",
    "    return 1\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    results = executor.map(take_name_and_prices, pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m2000\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     tam \u001b[39m=\u001b[39m sort[i] \u001b[39m+\u001b[39m loun[i]\n\u001b[0;32m      3\u001b[0m     loun[i]\u001b[39m=\u001b[39mtam\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(0,2000):\n",
    "    tam = sort[i] + loun[i]\n",
    "    loun[i]=tam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort2= []\n",
    "img = []\n",
    "loa=[]\n",
    "genre=[]\n",
    "def take_picture_info_genre(url):    \n",
    "    try:\n",
    "        urlnew = url[4:]\n",
    "        html = urlopen(urlnew)\n",
    "        soul = BeautifulSoup(html.read(), 'html.parser')\n",
    "        \n",
    "        try:\n",
    "            sort2.append(url[0:4])\n",
    "        except:\n",
    "            sort2.append(url[0:4])\n",
    "            \n",
    "        try:\n",
    "            tam = soul.find('div',class_='ToggleContent__View-sc-1dbmfaw-0 wyACs')\n",
    "            loa.append(tam.text)\n",
    "        except:\n",
    "            loa.append('')\n",
    "        try:\n",
    "            s=soul.find('picture',class_='webpimg-container')\n",
    "            ptd=s.find('img')\n",
    "            img.append(ptd['src'])\n",
    "        except:\n",
    "            img.append('')\n",
    "\n",
    "        try:\n",
    "            temp = []\n",
    "            for ptd in soul.find_all('a', class_ ='breadcrumb-item'):\n",
    "                temp.append(ptd.text)\n",
    "            genre.append(temp)\n",
    "        except:\n",
    "            genre.append('')\n",
    "    except : \n",
    "        loa.append('')\n",
    "        img.append('')\n",
    "        genre.append('')\n",
    "        sort2.append(url[0]+url[1]+url[2]+url[3])\n",
    "    return 1\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    results = executor.map(take_picture_info_genre, loun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2000):\n",
    "    for j in range(0,i):\n",
    "        if (sort[i]<sort[j]):\n",
    "            sort[i],sort[j]=sort[j],sort[i]\n",
    "            lon[i],lon[j]=lon[j],lon[i]\n",
    "            lop[i],lop[j]=lop[j],lop[i]\n",
    "for i in range(0,2000):\n",
    "    for j in range(0,i):\n",
    "        if (sort2[i]<sort2[j]):\n",
    "            sort2[i],sort2[j]=sort2[j],sort2[i]\n",
    "            img[i],img[j]=img[j],img[i]\n",
    "            loa[i],loa[j]=loa[j],loa[i]\n",
    "            genre[i],genre[j]=genre[j],genre[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pro={\"Tên \": lon,\"Gia \": lop,\"Thong Tin\":loa,\"Ảnh \":img,\"genre\":genre}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(dict_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"lgh1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE CŨ (CHẬM VCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon=[]\n",
    "lop=[]\n",
    "loun=[]\n",
    "loa=[]\n",
    "img = []\n",
    "genre = []\n",
    "def Webscraping(trang):\n",
    "    goc='https://tiki.vn/search?q=ti%E1%BB%83u+thuy%E1%BA%BFt&sort=top_seller&page=' \n",
    "    for i in range(1,trang+1): \n",
    "        html=urlopen(goc+str(i)) \n",
    "        bs = BeautifulSoup(html.read(), 'html.parser') \n",
    "        tam = bs.find_all('div',class_='name')\n",
    "        for i in tam :\n",
    "            lon.append(i.text)\n",
    "            \n",
    "        product_prices=bs.find_all('div',class_='price-discount__price')\n",
    "        \n",
    "        for element in product_prices:\n",
    "            lop.append(element.text)\n",
    "        \n",
    "        site='https://tiki.vn'\n",
    "        lou=[]\n",
    "        \n",
    "        urls=bs.find_all('a', class_='product-item')    \n",
    "        for url in urls:\n",
    "            lou.append(url['href']) \n",
    "        for url in lou:    \n",
    "            urlnew='{}{}'.format(site, url)\n",
    "            loun.append(urlnew)\n",
    "            html = urlopen(urlnew)\n",
    "            soul = BeautifulSoup(html.read(), 'html.parser')\n",
    "            try:\n",
    "                tam = soul.find('div',class_='ToggleContent__View-sc-1dbmfaw-0 wyACs')\n",
    "                loa.append(tam.text)\n",
    "            except : \n",
    "                loa.append('')\n",
    "\n",
    "            try :\n",
    "                s=soul.find('picture',class_='webpimg-container')\n",
    "                ptd=s.find('img')\n",
    "                img.append(ptd['src'])\n",
    "            except:\n",
    "                img.append('')\n",
    "            try:\n",
    "                temp = []\n",
    "                for ptd in soul.find_all('a', class_ ='breadcrumb-item'):\n",
    "                    temp.append(ptd.text)\n",
    "                genre.append(temp)\n",
    "            except:\n",
    "                genre.append('')\n",
    "        \n",
    "    dict_pro={\"Tên \": lon,\"Gia \": lop ,\"Thong tin\": loa,\"Anh\":img,\"The loai\":genre}\n",
    "    return dict_pro\n",
    "\n",
    "df=pd.DataFrame(Webscraping(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"lgh.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "839e0350e26a03edc91ebdedcb53fe8f541802bd102f926973002a967871fd0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
